<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>A beginner’s guide to regular expressions with grep</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/09/14/beginners-guide-regular-expressions-grep" /><author><name>Bob Reselman</name></author><id>d2745cb9-0e7f-4c18-88b2-a5ce98fb99ac</id><updated>2022-09-14T07:00:00Z</updated><published>2022-09-14T07:00:00Z</published><summary type="html">&lt;p&gt;A &lt;em&gt;regular expression&lt;/em&gt; (also called a &lt;em&gt;regex&lt;/em&gt; or &lt;em&gt;regexp&lt;/em&gt;) is a rule that a computer can use to match characters or groups of characters within a larger body of text. For instance, using regular expressions, you could find all the instances of the word &lt;em&gt;cat&lt;/em&gt; in a document, or all instances of a word that begins with &lt;em&gt;c&lt;/em&gt; and ends with &lt;em&gt;t.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Use of regular expressions in the real world can get much more complex—and powerful—than that. For example, imagine you need to write code verifying that all content in the body of an HTTP POST request is free of script injection attacks. Malicious code can appear in any number of ways, but you know that injected script code will always appear between &lt;code&gt;&lt;script&gt;&lt;/script&gt;&lt;/code&gt; HTML tags. You can apply the regular expression &lt;code&gt;&lt;script&gt;.*&lt;\/script&gt;&lt;/code&gt;, which matches any block of code text bracketed by &lt;code&gt;&lt;script&gt;&lt;/code&gt; tags, to the HTTP request body as part of your search for script injection code.&lt;/p&gt; &lt;p&gt;This example is but one of many uses for regular expressions. In this series, you'll learn more about how the syntax for this and other regular expressions work.&lt;/p&gt; &lt;p&gt;As just demonstrated, a regex can be a powerful tool for finding text according to a particular pattern in a variety of situations. Once mastered, regular expressions provide developers with the ability to locate patterns of text in source code and documentation at design time. You can also apply regular expressions to text that is subject to algorithmic processing at runtime such as content in HTTP requests or event messages.&lt;/p&gt; &lt;p&gt;Regular expressions are supported by many programming languages, as well as classic command-line applications such as &lt;a href="https://www.redhat.com/sysadmin/linux-text-manipulation-tools"&gt;awk, sed, and grep&lt;/a&gt;, which were developed for Unix many decades ago and are now offered on GNU/Linux.&lt;/p&gt; &lt;p&gt;This article examines the basics of using regular expressions under &lt;code&gt;grep&lt;/code&gt;. The article shows how you can use a regular expression to declare a pattern that you want to match, and outlines the essential building blocks of regular expressions, with many examples. This article assumes no prior knowledge of regular expressions, but you should understand how to with the &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; operating system at the command line.&lt;/p&gt; &lt;h2&gt;What are regular expressions, and what is grep?&lt;/h2&gt; &lt;p&gt;As we've noted, a regular expression is a rule used for matching characters in text. These rules are &lt;em&gt;declarative,&lt;/em&gt; which means they are immutable: once declared, they do not change. But a single rule can be applied to any variety of situations.&lt;/p&gt; &lt;p&gt;Regular expressions are written in a special language. Although this language has been standardized, dialects vary from one regular expression engine to another. For example, &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; has a regex dialect, as do &lt;a href="https://developers.redhat.com/topics/c"&gt;C++&lt;/a&gt;, &lt;a href="https://developers.redhat.com/java"&gt;Java&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article uses the regular expression dialect that goes with the Linux &lt;a href="https://www.redhat.com/sysadmin/how-to-use-grep"&gt;grep&lt;/a&gt; command, with an extension to support more powerful features. &lt;code&gt;grep&lt;/code&gt; is a binary executable that filters content in a file or output from other commands (stdout). Regular expressions are central to &lt;code&gt;grep&lt;/code&gt;: The &lt;em&gt;re&lt;/em&gt; in the middle of the name stands for "regular expression."&lt;/p&gt; &lt;p&gt;This article uses &lt;code&gt;grep&lt;/code&gt; because it doesn't require that you set up a particular coding environment or write any code to work with the examples of regular expressions demonstrated in this article. All you need to do is copy and paste an example onto the command line of a Linux terminal and you'll see results immediately. The &lt;code&gt;grep&lt;/code&gt; command can be used in any shell.&lt;/p&gt; &lt;p&gt;Because this article focuses on regular expressions as a language, and not on manipulating files, the examples use samples of text piped to &lt;code&gt;grep&lt;/code&gt; instead of input files.&lt;/p&gt; &lt;h3&gt;How to use grep against content in a file&lt;/h3&gt; &lt;p&gt;To print lines in a file that match a regular expression, use the following syntax:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ grep -options &lt;regular_expression&gt; /paths/to/files&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this command syntax:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-options&lt;/code&gt;, if specified, control the behavior of the command.&lt;/li&gt; &lt;li&gt;&lt;code&gt;&lt;regular_expression&gt;&lt;/code&gt; indicates the regular expression to execute against the files.&lt;/li&gt; &lt;li&gt;&lt;code&gt;/paths/to/files&lt;/code&gt; indicate one or more files against which the regular will be executed.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The options used in this article are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;-P&lt;/code&gt;: Apply regular expressions in the style of the Perl programming language. This option, which is specific to GNU/Linux, is used in the article to unlock powerful features that aren't recognized by &lt;code&gt;grep&lt;/code&gt; by default. There is nothing specific to Perl in the regular expressions used in this article; the same features can be found in many programming languages.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-i&lt;/code&gt;: Match in a case-insensitive manner.&lt;/li&gt; &lt;li&gt;&lt;code&gt;-o&lt;/code&gt;: Print only the characters matching the regular expression. By default, the whole line containing the matching string is printed.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;How to pipe content to a regular expression&lt;/h3&gt; &lt;p&gt;As mentioned earlier, you can also use a regular expression to filter output from stdout. The following example uses the pipe symbol (&lt;code&gt;|&lt;/code&gt;) to feed the result of an &lt;code&gt;echo&lt;/code&gt; command to &lt;code&gt;grep&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ echo "I like using regular expressions." | grep -Po 'r.*ar'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command produces the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;regular&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Why does &lt;code&gt;grep&lt;/code&gt; return the characters &lt;code&gt;regular&lt;/code&gt; to match the regular expression specified here? We'll explore the reasons in subsequent sections of this article.&lt;/p&gt; &lt;h2&gt;Regular characters, metacharacters, and patterns: The building blocks of regular expressions&lt;/h2&gt; &lt;p&gt;You'll use three basic building blocks when working with regular expressions: &lt;em&gt;regular characters, metacharacters,&lt;/em&gt; and &lt;em&gt;patterns.&lt;/em&gt; Regular characters and metacharacters are used to create a regular expression, and that regular expression represents a matching pattern that the regex engine applies to some content.&lt;/p&gt; &lt;p&gt;You can think of a metacharacter as a placeholder symbol. For example, the &lt;code&gt;.&lt;/code&gt; metacharacter (a dot or period) represents "any character." The &lt;code&gt;\d&lt;/code&gt; metacharacter represents any single numeral, 0 through 9.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;*&lt;/code&gt; metacharacter is a shorthand that represents the instruction "search for a character that occurs zero or more times as defined by the preceding character." (You'll see how to work with the &lt;code&gt;*&lt;/code&gt; metacharacter in sections to come.)&lt;/p&gt; &lt;p&gt;Regular expressions support many metacharacters, each worthy of a page or two of description. For now, the important thing to understand is that a metacharacter is a reserved symbol used by the regex engine to describe a character in a generic manner. Also, certain metacharacters are a shorthand for a search instruction.&lt;/p&gt; &lt;p&gt;You can combine regular characters with metacharacters to declare rules that define search patterns. For example, consider the following short regular expression:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;.t&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This matches a pattern consisting of two characters. The first character can be any character, as declared by the &lt;code&gt;.&lt;/code&gt; (dot) metacharacter, but the second character must be &lt;code&gt;t&lt;/code&gt;. Thus, applying the regular expression &lt;code&gt;.t&lt;/code&gt; to the string &lt;code&gt;I like cats but not rats&lt;/code&gt; matches the strings highlighted in bold font here:&lt;/p&gt; &lt;p&gt;&lt;code&gt;I like c&lt;strong&gt;at&lt;/strong&gt;s b&lt;strong&gt;ut&lt;/strong&gt; n&lt;strong&gt;ot&lt;/strong&gt; r&lt;strong&gt;at&lt;/strong&gt;s&lt;/code&gt;&lt;/p&gt; &lt;p&gt;You can do a lot using just the basic metacharacters to create regular expressions with &lt;code&gt;grep&lt;/code&gt;. The following sections provide a number of useful examples.&lt;/p&gt; &lt;h2&gt;Running basic regular expressions&lt;/h2&gt; &lt;p&gt;The following subsections demonstrate various examples of regular expressions. The examples are presented as two commands to enter in a Linux terminal. The first command creates a variable named &lt;code&gt;teststr&lt;/code&gt; that contains a sample string. The second executes the &lt;code&gt;echo&lt;/code&gt; command against &lt;code&gt;teststr&lt;/code&gt; and pipes the result of the &lt;code&gt;echo&lt;/code&gt; command to &lt;code&gt;grep&lt;/code&gt;. The &lt;code&gt;grep&lt;/code&gt; command then filters the input according to the associated regular expression.&lt;/p&gt; &lt;h3&gt;How to declare an exact pattern match using regular characters&lt;/h3&gt; &lt;p&gt;The following example demonstrates how to search a string according to the pattern of regular characters, &lt;code&gt;Fido&lt;/code&gt;. The search declaration is case-sensitive:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety." $ echo $teststr | grep -Po 'Fido'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;Fido&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to declare a case-insensitive exact pattern match&lt;/h3&gt; &lt;p&gt;The following example demonstrates how to search a string according to a pattern of regular characters, &lt;code&gt;fido&lt;/code&gt;. The search declaration is case-insensitive, as indicated by the &lt;code&gt;-i&lt;/code&gt; option in the &lt;code&gt;grep&lt;/code&gt; command. Thus, the regex engine will find occurrences such as &lt;code&gt;FIDO&lt;/code&gt; as well as &lt;code&gt;fido&lt;/code&gt; or &lt;code&gt;fiDo&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety." $ echo $teststr | grep -Poi 'fido'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;Fido&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to declare a logical pattern match&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;|&lt;/code&gt; metacharacter symbol to search according to a &lt;em&gt;this or that&lt;/em&gt; condition—that is, a condition that can be satisfied by either of the regular expressions on either side of &lt;code&gt;|&lt;/code&gt;. In this case, the regular expression matches occurrences of the regular character &lt;code&gt;f&lt;/code&gt; or &lt;code&gt;g&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety." $ echo $teststr | grep -Po 'f|g'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;grep&lt;/code&gt; command identifies each occurrence that satisfies the rule declared in the regular expression. Conceptually, the regular expression is saying, &lt;em&gt;Return any character that is either an f or a g&lt;/em&gt;. We are leaving the search case-sensitive, as is the default. Thus, the identified characters are highlighted in bold text here:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Je&lt;strong&gt;ff&lt;/strong&gt; and the pet Lucky. Gre&lt;strong&gt;gg&lt;/strong&gt; and the do&lt;strong&gt;g&lt;/strong&gt; Fido. Chris has 1 bird named Tweety.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Because each character is identified and returned on a one-by-one basis, the output sent to the terminal window is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;f f g g g&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to find a character at the beginning of a line&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;^&lt;/code&gt; metacharacter to search for the beginning of a line of text. Conceptually, the &lt;code&gt;^&lt;/code&gt; metacharacter matches the beginning of a line.&lt;/p&gt; &lt;p&gt;The example executes the regular expression &lt;code&gt;^J&lt;/code&gt;. This regular expression searches for a match that satisfies two conditions. The first condition is to find the beginning of the line; the next is to find the regular character &lt;code&gt;J&lt;/code&gt; at that position.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety." $ echo $teststr | grep -Po '^J'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The regular expression matches the character highlighted in bold text as shown here:&lt;/p&gt; &lt;p&gt;&lt;code&gt;&lt;strong&gt;J&lt;/strong&gt;eff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The result returned to the terminal is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;J&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to find a character at the end of a line&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;$&lt;/code&gt; metacharacter to search for the end of a line to text.&lt;/p&gt; &lt;p&gt;The example executes the regular expression &lt;code&gt;\.$&lt;/code&gt;. The regular expression declares a matching rule that has two conditions. First, the regular expression searches for an occurrence of the regular character &lt;code&gt;.&lt;/code&gt; (dot). Then the regular expression looks to see whether the end of the line is next. Thus, if the &lt;code&gt;.&lt;/code&gt; character comes at the end of the line, it's deemed a match.&lt;/p&gt; &lt;p&gt;The regular expression includes a backslash (&lt;code&gt;\&lt;/code&gt;) as an "escape" metacharacter before the dot. The escape metacharacter is needed to override the normal meaning of the dot as a metacharacter. Remember that the &lt;code&gt;.&lt;/code&gt; (dot) metacharacter means &lt;em&gt;any character&lt;/em&gt;. With the escape character, the dot is treated as a regular character, and so matches just itself:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety." $ echo $teststr | grep -Po '\.$'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The regular expression matches the final dot in the text, highlighted in bold as shown here:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety&lt;strong&gt;.&lt;/strong&gt;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;The result is just the final dot:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Suppose you were to use an unescaped dot in the regular expression:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ echo $teststr | grep -Po '.$'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You would get the same result as using the escaped dot, but a different logic is being executed. That logic is: &lt;em&gt;Match any character that is the last character before the end of the string&lt;/em&gt;. Thus, the regular expression would always match any line. Using the escape character to identify a character as a regular character is a subtle distinction in this case, but an important one nonetheless.&lt;/p&gt; &lt;h3&gt;How to find multiple characters at the end of a line&lt;/h3&gt; &lt;p&gt;The following example searches the string assigned to the variable &lt;code&gt;teststr&lt;/code&gt; to match the characters &lt;code&gt;ty.&lt;/code&gt; when they appear at the end of a line.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="Jeff and the pet Lucky. Gregg and the dog Fido. Chris has 1 bird named Tweety." $ echo $teststr | grep -Po 'ty\.$'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;ty.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Again, note the user of the escape metacharacter (&lt;code&gt;\&lt;/code&gt;) to declare the &lt;code&gt;.&lt;/code&gt; (dot) character as a regular character.&lt;/p&gt; &lt;h3&gt;How to find occurrences of a character using the metacharacters for matching numerals&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;\d&lt;/code&gt; metacharacter to create a regular expression that looks for matches of any numeral in a given piece of text.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="There are 9 cats and 2 dogs in a box." $ echo $teststr | grep -Po '\d'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Because each numeral is matched and returned on a one-by-one basis, the output sent to the terminal is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;9 2&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to find a string using metacharacters for a numeral and a space&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;\d &lt;/code&gt;and &lt;code&gt;\s&lt;/code&gt; metacharacters along with regular characters to create a regular expression that matches text according to the following logic: &lt;em&gt;Match any numeral that is followed by a space and then the regular characters &lt;/em&gt;&lt;strong&gt;&lt;em&gt;cats&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;\d&lt;/code&gt; metacharacter matches a numeral and the &lt;code&gt;\s&lt;/code&gt; metacharacter matches a whitespace character (a space, a tab, or a few other rare characters):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="There are 9 cats and 2 dogs in a box." $ echo $teststr | grep -Po '\d\scats'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;9 cats&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to combine metacharacters to create a complex regular expression&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;\d&lt;/code&gt; metacharacter to match a numeral, &lt;code&gt;\s&lt;/code&gt; to match a space, and &lt;code&gt;.&lt;/code&gt; (dot) to match any character. The regular expressions uses the &lt;code&gt;*&lt;/code&gt; metacharacter to say, &lt;em&gt;Match zero or more successive occurrences of the preceding character.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The logic expressed in the regular expression is this: &lt;em&gt;Find a string of text that starts with a numeral followed by a space character and the regular characters &lt;strong&gt;cats.&lt;/strong&gt; Then keep going, matching any characters until you come to another numeral followed by a space character and the regular characters &lt;strong&gt;dogs&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="There are 9 cats and 2 dogs in a box." $ echo $teststr | grep -Po '\d\scats.*\d\sdogs'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;9 cats and 2 dogs&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;How to traverse a line of text to a stop point&lt;/h3&gt; &lt;p&gt;The following example uses the &lt;code&gt;.&lt;/code&gt; (dot) metacharacter and &lt;code&gt;*&lt;/code&gt; along with the regular characters &lt;code&gt;cats&lt;/code&gt; to create a regular expression with the following logic: &lt;em&gt;Match any character zero or more times until you come to the characters &lt;strong&gt;cats&lt;/strong&gt;&lt;/em&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ teststr="There are 9 cats and 2 dogs in a box." $ echo $teststr | grep -Po '.*cats'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result is:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;There are 9 cats&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The interesting thing about this regular expression is that starting from the beginning of the line is implicit. The &lt;code&gt;^&lt;/code&gt; metacharacter could be used to indicate the start of a line, but because the regular expression matches any characters until you come to &lt;code&gt;cats&lt;/code&gt;, it isn't necessary to explicitly declare the start of the line using &lt;code&gt;^&lt;/code&gt;. The regular expression starts processing from the beginning of the line by default.&lt;/p&gt; &lt;h2&gt;Regular expressions uncover patterns in text&lt;/h2&gt; &lt;p&gt;Regular expressions offer a powerful yet concise way to do complex text filtering. You can use them in programming languages such as JavaScript, Python, Perl, and C++, and directly in a Linux terminal to process files and text using the &lt;code&gt;grep&lt;/code&gt; command, as demonstrated in this article.&lt;/p&gt; &lt;p&gt;Getting the hang of regular expressions takes time. Mastering the intricacies of working with the metacharacters alone can be daunting. Fortunately, the learning curve is developmental. You don't have to master the entirety of regular expressions to work with them usefully as a beginner. You can start with the basics, and as you learn more you can do more. Just being able to do pattern matching using the basic examples shown in this article can provide immediate benefit.&lt;/p&gt; &lt;p&gt;An upcoming article in this series will explain regular expression features that are even more powerful.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/09/14/beginners-guide-regular-expressions-grep" title="A beginner’s guide to regular expressions with grep"&gt;A beginner’s guide to regular expressions with grep&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bob Reselman</dc:creator><dc:date>2022-09-14T07:00:00Z</dc:date></entry><entry><title type="html">Remote dev-watch development with WildFly Jar Maven Plugin</title><link rel="alternate" href="https://wildfly.org//news/2022/09/14/Remote-dev-watch/" /><author><name>Emmanuel Hugonnet</name></author><id>https://wildfly.org//news/2022/09/14/Remote-dev-watch/</id><updated>2022-09-14T00:00:00Z</updated><content type="html">The 8.0.0.Alpha2 version of the has been released. This is not yet Final, as it is only there to gather feedback on a new feature that simplifies development on the "cloud" using the dev-watch goal. For people who are not familiar with WildFly bootable JAR and its dev-watch goal, I strongly recommend that you read this that covers it in details. DEV-WATCH GOAL The current dev-watch goal, although offering an efficient workflow to develop WildFly applications, requires the bootable application or server to run locally, in the same place as the project. The improvement made on this release is to allow the bootable application or server to run remotely so that it can be in an environment that is closer to the target runtime environment. We are going to use to see how we can work remotely. Important This application applies the script anonymous-management.cli which disable security on the Management API of WildFly, please make sure not to include it when going to production. DEVELOPPING WITH A DOCKER CONTAINER. BUILD AND RUN THE APPLICATION WITH DOCKER The first step is to create the container image where the application is running. For this we are going to use a very simple Dockerfile: FROM registry.access.redhat.com/ubi8/openjdk-11:latest COPY --chown=jboss:root target/*.jar /deployments/. RUN chmod -R ug+rwX /deployments/. To build that container image we are executing: $ mvn clean install $ podman build -f Dockerfile -t remote-microprofile-config:latest And then we are going to run the container and expose the ports 8080 and 9990: $ podman run -p 8080:8080 -p 9990:9990 -it remote-microprofile-config:latest DEVELOP AND UPDATE THIS APPLICATION Now we need to run the dev-watch goal and remotely attach to the Wildfly Management API. For this we need to execute the following command line: $ mvn org.wildfly.plugins:wildfly-jar-maven-plugin:8.0.0.Alpha2:dev-watch \ -Dwildfly.bootable.remote=true \ -Dwildfly.bootable.remote.username=admin \ -Dwildfly.bootable.remote.password=passW0rd! \ -Dwildfly.hostname=${container.ip.address} Check that the application is running properly : $ curl http://${container.ip.address}:8080 config1 = Value from Config1 comes from an env var in the DeploymentConfig config2 = Value for config2 comes from a properties file inside the application config3 = Default value for config3 comes from my code Once this is done you can edit the code and your changes will be automatically pushed to the remote container. For example: * Change the config2 property value to be "Hello from dev-watch remote" in the file: src/main/resources/META-INF/microprofile-config.properties. * Save your changes * The application is redeployed and the new configuration will be taken into account: $ curl http://${container.ip.address}:8080 config1 = Value from Config1 comes from an env var in the DeploymentConfig config2 = Hello from dev-watch remote config3 = Default value for config3 comes from my code DEVELOPPING ON OPENSHIFT. BUILD AND RUN THE APPLICATION WITH OPENSHIFT We first need to build the application : $ mvn clean install Then to deploy it you need to drag and drop the produced remote-microprofile-config-bootable.jar on the Topology page on OpenShift. Now we need to expose the management API of WilFly by first editing the service to add a TCP port for 9990, and then add a route to that port: $ oc create route edge management-remote-microprofile-config-bootable --service=remote-microprofile-config-bootable --port=9990 --insecure-policy='Redirect' DEVELOP AND UPDATE THIS APPLICATION Now we need to run the dev-watch goal and remotely attach to the Wildfly Management API. For this we need to execute the following command line: $ mvn -P bootable-jar-remote -Dwildfly.hostname=$(oc get route management-remote-microprofile-config-bootable --template='{{ .spec.host }}') install You may also use a command like this one: $ mvn org.wildfly.plugins:wildfly-jar-maven-plugin:8.0.0.Alpha2:dev-watch \ -Dwildfly.bootable.remote=true \ -Dwildfly.port=443 \ -Dwildfly.bootable.remote.protocol=remote+https \ -Dwildfly.hostname=$(oc get route management-remote-microprofile-config-bootable --template='{{ .spec.host }}') Check that the application is running properly : $ curl https://$(oc get route remote-microprofile-config-bootable --template='{{ .spec.host }}') config1 = Value from Config1 comes from an env var in the DeploymentConfig config2 = Value for config2 comes from a properties file inside the application config3 = Default value for config3 comes from my code Once this is done you can edit the code and your changes will be automatically pushed to the OpenShift instance. For example: * Change the config2 property value to be "Hello from dev-watch remote" in the file: src/main/resources/META-INF/microprofile-config.properties. * Save your changes * The application is redeployed and the new configuration will be taken into account: $ curl https://$(oc get route remote-microprofile-config-bootable --template='{{ .spec.host }}') config1 = Value from Config1 comes from an env var in the DeploymentConfig config2 = Hello from dev-watch remote config3 = Default value for config3 comes from my code CONCLUSION We hope that you are seeing the benefits of the new features that this release is bringing. We would really appreciate your on the dev-watch goal. We aim toward a smooth and efficient first class WildFly developer experience and we need you there! Thank-you.</content><dc:creator>Emmanuel Hugonnet</dc:creator></entry><entry><title>Kafka Monthly Digest: August 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/09/13/kafka-monthly-digest-august-2022" /><author><name>Mickael Maison</name></author><id>195c9344-8250-48a9-9554-85515b7d00a9</id><updated>2022-09-13T07:00:00Z</updated><published>2022-09-13T07:00:00Z</published><summary type="html">&lt;p&gt;This 55th edition of the &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Kafka&lt;/a&gt; Monthly Digest covers what happened in the &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; community in August 2022.&lt;/p&gt; &lt;p&gt;For last month’s digest, see &lt;a href="https://developers.redhat.com/articles/2022/08/04/kafka-monthly-digest-july-2022"&gt;Kafka Monthly Digest: July 2022&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Releases&lt;/h2&gt; &lt;p&gt;There is currently one release in progress, 3.3.0.&lt;/p&gt; &lt;h3&gt;3.3.0&lt;/h3&gt; &lt;p&gt;The release process for 3.3.0 continued. José Armando García Sancio published the first release candidate on August 29. A few issues, including &lt;a href="https://issues.apache.org/jira/browse/KAFKA-14187"&gt;KAFKA-14187&lt;/a&gt; and &lt;a href="https://issues.apache.org/jira/browse/KAFKA-14156"&gt;KAFKA-14156&lt;/a&gt;, were found during testing, so José built RC1 on September 1. The vote is currently ongoing. You can find the &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release+Plan+3.3.0"&gt;release plan&lt;/a&gt; in the wiki.&lt;/p&gt; &lt;h2&gt;Kafka Improvement Proposals&lt;/h2&gt; &lt;p&gt;Last month, the community submitted three &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals"&gt;Kafka Improvement Proposals (KIPs)&lt;/a&gt; (KIP-863 to KIP-865). I'll highlight a couple of them:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-864%3A+Add+End-To-End+Latency+Metrics+to+Connectors"&gt;KIP-864: Add End-To-End Latency Metrics to Connectors&lt;/a&gt;. This KIP proposes adding a few new metrics to track end-to-end latency for records flowing through Connect. This would also include metrics tracking the time spent in converters.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-865%3A+Support+--bootstrap-server+in+kafka-streams-application-reset"&gt;KIP-865: Support --bootstrap-server in kafka-streams-application-reset&lt;/a&gt;. This very small KIP aims at addressing a discrepancy with the &lt;code&gt;kafka-streams-application-reset.sh&lt;/code&gt; tool. This tool currently uses the &lt;code&gt;--bootstrap-servers&lt;/code&gt; flag, while all other tools use &lt;code&gt;--bootstrap-server&lt;/code&gt;, so it will be updated for consistency.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Community releases&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/tchiotludo/akhq/releases/tag/0.22.0"&gt;akhq 0.22&lt;/a&gt;: AKHQ is a GUI for Apache Kafka. This new version adds a few new features, including support for listing ACLs on Cluster and TransactionalIds and sending Protobuf records via the UI.&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/tulios/kafkajs/releases/tag/v2.2.0"&gt;kafkajs 2.2.0&lt;/a&gt;: Kafkajs is a pure JavaScript Kafka client for Node.js. This release adds support for triggering and listing partition reassignments in its Admin API and contains a few fixes.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Blogs&lt;/h2&gt; &lt;p&gt;I selected some interesting blog articles that were published last month:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://towardsdatascience.com/machine-learning-streaming-with-kafka-debezium-and-bentoml-c5f3996afe8f"&gt;Machine Learning Streaming with Kafka, Debezium, and BentoML&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/event-driven-utopia/building-cqrs-views-with-debezium-kafka-materialize-and-apache-pinot-part-1-4f697735b2e4"&gt;Building CQRS Views with Debezium, Kafka, Materialize, and Apache Pinot — Part 1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/event-driven-utopia/building-cqrs-views-with-debezium-kafka-materialize-and-apache-pinot-part-2-6899e9efc74e"&gt;Building CQRS Views with Debezium, Kafka, Materialize, and Apache Pinot — Part 2&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To learn more about Kafka, visit &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Red Hat Developer's Apache Kafka topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/09/13/kafka-monthly-digest-august-2022" title="Kafka Monthly Digest: August 2022"&gt;Kafka Monthly Digest: August 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Mickael Maison</dc:creator><dc:date>2022-09-13T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus adoption by APHP (Assistance Publique des Hôpitaux de Paris)</title><link rel="alternate" href="https://quarkus.io/blog/aphp-user-story/" /><author><name>Jean-Yves Terrien</name></author><id>https://quarkus.io/blog/aphp-user-story/</id><updated>2022-09-13T00:00:00Z</updated><content type="html">About APHP L’Assistance Publique - Hôpitaux de Paris, AP-HP is an internationally oriented university hospital center. Some numbers (2020) : 38 Hospitals 1 public healthcare service working 24/7 6,9 million patients 100 000 health professionals taking care of our patients - including nearly 12 200 doctors, 4 000 interns, over...</content><dc:creator>Jean-Yves Terrien</dc:creator></entry><entry><title type="html">How to spot Java bugs with SpotBugs</title><link rel="alternate" href="http://www.mastertheboss.com/java/how-to-spot-java-bugs-with-spotbugs/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/how-to-spot-java-bugs-with-spotbugs/</id><updated>2022-09-12T07:47:00Z</updated><content type="html">This article will introduce you to SpotBugs utility project that can assist you to spot Java “bug patterns” in your code which are likely to turn into runtime bugs. Getting started with SpotBugs Firstly, let’s see how SpotBugs works. This tool uses defines a set of Bug patterns that will be scanned in your code ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">RESTEasy 6.2.0.Beta1 Release</title><link rel="alternate" href="https://resteasy.github.io/2022/09/08/resteasy-6.2.0.Beta1-release/" /><author><name /></author><id>https://resteasy.github.io/2022/09/08/resteasy-6.2.0.Beta1-release/</id><updated>2022-09-08T18:11:11Z</updated><dc:creator /></entry><entry><title type="html">This Week in JBoss - 08 September 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-09-08.html" /><category term="quarkus" /><category term="wildfly" /><category term="java" /><category term="wildfly" /><category term="kogito" /><category term="hibernate" /><author><name>Jason Porter</name><uri>https://www.jboss.org/people/jason-porter</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-09-08.html</id><updated>2022-09-08T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, wildfly, java, wildfly, kogito, hibernate"&gt; &lt;h1&gt;This Week in JBoss - 08 September 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Welcome back, glad to have you back with us this week! Progress continues to happen at JBoss, and Red Hat. We have some releases, blogs, and a couple of videos as well.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases"&gt;Releases&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-12-0-final-released/"&gt;Quarkus 2.12.0&lt;/a&gt; - GraalVM/Mandrel 22.2, Kotlin 1.7, Smallrye Config SecretKeys, and SQL Server JDBC Driver update&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-12-1-final-released/"&gt;Quarkus 2.12.1&lt;/a&gt; - A performance regression fix&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://in.relation.to/2022/09/08/hibernate-orm-613-final/"&gt;Hibernate ORM 6.1.3&lt;/a&gt; - Maintenance release&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://in.relation.to/2022/08/30/hibernate-orm-5611-final/"&gt;Hibernate ORM 5.6.11&lt;/a&gt; - Maintenance release (includes performance fixes)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/09/kogito-1-27-0-released.html"&gt;Kogito 1.27.0&lt;/a&gt; - New feature release&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org//news/2022/08/31/WildFly2612-Released/"&gt;Wildfly 26.1.2&lt;/a&gt; - Maintenance release&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_blogs"&gt;Blogs&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/09/monitoring-quarkus-applications-with-dashbuilder.html"&gt;Monitoring Quarkus Applications With Dashbuilder&lt;/a&gt; - Building dashboards using DashBuilder&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/redis-api-intro/"&gt;Introducing the new Redis API - How to cache with Redis?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/09/operator-crs"&gt;The future of Keycloak Operator CRs&lt;/a&gt; - Looking at the new way of managing Keycloak resources&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://wildfly-security.github.io/wildfly-elytron/blog/bearer-only-support-openid-connect/"&gt;Bearer Token Support for the Elytron OIDC Client Subsystem&lt;/a&gt; - Learn how to update your application to support Bearer Tokens using OIDC (OpenID Connect)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://wildfly-security.github.io/wildfly-elytron/blog/top-five-reasons-to-join-elytron-open-source-day/"&gt;Top 5 Reasons To Join Us At Open Source Day&lt;/a&gt; - September 16 is Open Source Day! Wildfly Electron was selected as a project for this day long hackathon&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/cool-stuff/mongodb/building-java-enteprise-applications-using-mongodb/"&gt;Building Java Enterprise applications using MongoDB&lt;/a&gt; - Dig into MongoDB in a Jakarta EE Application&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/08/25/optimize-loops-long-variables-java"&gt;Optimize loops with long variables in Java&lt;/a&gt; - A look into JVM loop optimizations&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_videos"&gt;Videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=NJglcdL9m7A"&gt;Quarkus Insights #100: EDDI chatbot goes cloud-native with Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_until_next_time"&gt;Until next time!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Everyone stay safe out there, and we look forward to seeing you in two weeks for our next edition!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/jason-porter.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Jason Porter&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Jason Porter</dc:creator></entry><entry><title type="html">Kogito 1.27.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/09/kogito-1-27-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/09/kogito-1-27-0-released.html</id><updated>2022-09-07T12:42:31Z</updated><content type="html">We are glad to announce that the Kogito 1.27.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Adding patch http method for process instance. This allows partial updates of the process model.  * Variable change events are more specific, only the changed value of the Workflow model is published rather than the whole object * Kogito now supports injection of multiple WorkItemHandlerConfig instances * Fix ArrayNode merging to replace the whole array. This prevents duplication of values.  * Clone procedure performance has been improved.    * Exceptions thrown by an action can be stored into a process variable for BPMN.  KNOWN ISSUE(S) * Quarkus SVG addon fails to compile in native mode, see * WorkItemNotFoundException when running OpenAPI generated client in dev mode, see * ClassNotFoundException in enum persistence For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.22.0 artifacts are available at the . A detailed changelog for 1.27.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>Red Hat OpenShift Connectors: Configuring change data capture</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/09/07/configuring-change-data-capture" /><author><name>Bernard Tison</name></author><id>41f98b40-5aa6-451e-9c6d-2655264e4f6a</id><updated>2022-09-07T07:00:00Z</updated><published>2022-09-07T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/connectors"&gt;Red Hat OpenShift Connectors&lt;/a&gt; is a new cloud service offering from Red Hat. The service provides prebuilt connectors to enable quick and reliable connectivity across data, services, and systems. Each connector is a fully managed service, tightly integrated with &lt;a href="https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/overview"&gt;Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt;, Red Hat's managed cloud service for Apache Kafka.&lt;/p&gt; &lt;p&gt;Change data capture (CDC) is a software process that detects changes (inserts, updates, deletes) to data in a database and transforms these changes into event streams that can be consumed by other systems or applications to react to these changes.&lt;/p&gt; &lt;p&gt;Typical use cases for change data capture include: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Data replication&lt;/li&gt; &lt;li&gt;Streaming analytics&lt;/li&gt; &lt;li&gt;Event-driven distributed applications&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Red Hat OpenShift Connectors offers several source connectors for change data capture, based on the popular &lt;a href="https://debezium.io/"&gt;Debezium&lt;/a&gt; open source project. OpenShift Connectors support the following databases:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;PostgreSQL&lt;/li&gt; &lt;li&gt;MySQL&lt;/li&gt; &lt;li&gt;SQL Server&lt;/li&gt; &lt;li&gt;MongoDB&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This article demonstrates how to configure a source connector to capture data change events from &lt;a href="https://www.mongodb.com/cloud"&gt;MongoDB Atlas&lt;/a&gt;, a fully managed cloud database provided by MongoDB.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;This article assumes that you have created an instance of OpenShift Streams for Apache Kafka and that the instance is in the &lt;code&gt;Ready&lt;/code&gt; state. Please refer to &lt;a href="https://developers.redhat.com/articles/2021/07/07/getting-started-red-hat-openshift-streams-apache-kafka"&gt;Getting started with Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt; for step-by-step instructions on creating your Kafka instance.&lt;/p&gt; &lt;p&gt;Create a service account and configure the access rules for it. The service account requires privileges to read and write topics and to create new topics. The &lt;a href="https://developers.redhat.com/articles/2022/06/09/get-started-red-hat-openshift-connectors"&gt;Get started with Red Hat OpenShift Connectors&lt;/a&gt; article has detailed instructions on creating and configuring the service account and the access rules.&lt;/p&gt; &lt;h2&gt;Set up a MongoDB Atlas instance&lt;/h2&gt; &lt;p&gt;The following instructions will guide you through the process of setting up a MongoDB Atlas instance:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.mongodb.com/cloud/atlas/register"&gt;Sign up&lt;/a&gt; to provision a MongoDB Atlas instance. You can create an Atlas account or sign up with your Google account.&lt;/li&gt; &lt;li&gt;After registration, you are taken to a page where you can choose the type of cloud database you want to provision. MongoDB Atlas offers different tiers, including a free tier for an easy getting-started experience. The free tier is sufficient to follow this demonstration.&lt;/li&gt; &lt;li&gt;When creating your MongoDB Atlas instance, you have to specify the security settings. Choose a username&lt;strong&gt; &lt;/strong&gt;and password and create a user to connect to your MongoDB instance.&lt;/li&gt; &lt;li&gt;Add an IP address to the &lt;strong&gt;IP Access List&lt;/strong&gt;. Enter &lt;code&gt;0.0.0.0/0 &lt;/code&gt; because you don't know the IP address where the managed OpenShift Connector is running. This effectively allows connections to your MongoDB instance from anywhere. You can make the IP Access List more restrictive later on.&lt;/li&gt; &lt;li&gt;Add databases and collections once the MongoDB Atlas instance is up and running.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;MongoDB Atlas provides a sample dataset described &lt;a href="https://www.mongodb.com/docs/atlas/sample-data/"&gt;in the documentation&lt;/a&gt;. We will use the &lt;code&gt;sample_mflix&lt;/code&gt; database from the sample dataset. This dataset contains data about movies.&lt;/p&gt; &lt;h2&gt;10 steps to create an instance for change data capture&lt;/h2&gt; &lt;p&gt;Now that you have provisioned and configured a MongoDB Atlas instance and loaded the sample dataset, you can create an OpenShift Connectors source connector to capture change events from the &lt;code&gt;sample_mflix&lt;/code&gt; database. From your &lt;a href="https://console.redhat.com"&gt;Red Hat console&lt;/a&gt;, complete the following 10 steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; &lt;p&gt;Select &lt;strong&gt;Application and Data Services&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;On the &lt;strong&gt;Application and Data Services&lt;/strong&gt; page, select &lt;strong&gt;Connectors&lt;/strong&gt; and click &lt;strong&gt;Create Connectors instance&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;To find the &lt;strong&gt;Debezium MongoDB&lt;/strong&gt; connector, enter &lt;code&gt;mongo&lt;/code&gt; in the search field. Click the &lt;strong&gt;Debezium MongoDB Connector&lt;/strong&gt; card, then click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Select the &lt;strong&gt;Streams for Apache Kafka&lt;/strong&gt; instance for the connector. (This is the instance you created in the prerequisites step.) Then click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;On the &lt;strong&gt;Namespace&lt;/strong&gt; page, click &lt;strong&gt;Create preview namespace&lt;/strong&gt; to provision a namespace for hosting the connector instances that you create (or select your existing namespace if you created one earlier). This evaluation namespace will remain available for 48 hours. You can create up to four connector instances per namespace. Once the namespace is available, select it and click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provide the core configuration for your connector by entering the following values:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;A unique name for the connector.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The &lt;strong&gt;Client ID&lt;/strong&gt; and &lt;strong&gt;Client Secret&lt;/strong&gt; of the service account that you created for your connectors.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Provide the connection configuration for your connector. For the &lt;strong&gt;Debezium MongoDB&lt;/strong&gt; connector, enter the following information:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hosts&lt;/strong&gt;: The set of the replicaset public addresses for your MongoDB instance. You can find these on the web console for your MongoDB instance. Click the &lt;strong&gt;Overview&lt;/strong&gt; tab shown in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/mongo-replicaset.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/mongo-replicaset.png?itok=CpbJzBQ2" width="600" height="262" alt="A screenshot of the public addresses for the MongoDB replicaset. " loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Overview tab on the web console of the MongoDB Atlas instance shows the public addresses of the MongoDB replicaset. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Click the first link to get to the status page of the replica. The address of the replica is shown at the top of the page in &lt;code&gt;host:port&lt;/code&gt; format. Copy the address to a text editor.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Repeat the procedure for the other replicas.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Go back to the OpenShift Connectors configuration page and enter the addresses of the three replicas separated by commas in the &lt;strong&gt;Hosts&lt;/strong&gt; field. The entry should look like the following list (your values will be different):&lt;/p&gt; &lt;p&gt;&lt;code class="java"&gt;ac-whrxxxx-shard-00-00.ooulprt.mongodb.net:27017, ac-whrxxxx-shard-00-01.ooulprt.mongodb.net:27017, ac-whrxxxx-shard-00-02.ooulprt.mongodb.net:27017&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Namespace&lt;/strong&gt;: A unique name that identifies this MongoDB instance. For example, enter &lt;code&gt;mongo-mflix&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Password&lt;/strong&gt;: The password of the database user you created previously. Note that this is not the same user with which you logged into MongoDB Atlas.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;User&lt;/strong&gt;: The user name of the database user you created.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Make sure the &lt;strong&gt;Enable SSL connection to MongoDB&lt;/strong&gt; is checked.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 2 shows what a filled-out form looks like.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image1_12.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image1_12.png?itok=Ebn64xZ_" width="600" height="348" alt="A screenshot of configuration properties for MongoDB Debezium connector." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Enter configuration properties for the MongoDB Debezium connector. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;On the next page of the wizard, set the &lt;strong&gt;Database filter&lt;/strong&gt; to &lt;code&gt;sample_mflix&lt;/code&gt; and the &lt;strong&gt;Collection filter&lt;/strong&gt; to &lt;code&gt;sample_mflix.movies. &lt;/code&gt; This will ensure you capture change events only from the &lt;code&gt;movies&lt;/code&gt; collection.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Make sure that the &lt;strong&gt;Include&lt;/strong&gt; box is selected for both entries. Click &lt;strong&gt;Apply&lt;/strong&gt; to apply the filter. [Do not change the values on the &lt;strong&gt;Data &amp; runtime&lt;/strong&gt; page of the wizard. These are advanced values that you rarely need to change.]&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Review the summary of the configuration properties. Pay particular attention to the MongoDB &lt;strong&gt;Hosts&lt;/strong&gt; field. Click &lt;strong&gt;Create Connector&lt;/strong&gt; to create the connector.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Your connector instance will be added to the table of connectors. After a couple of seconds, the status of your connector instance should change to &lt;code&gt;Ready&lt;/code&gt;. If your connector ends up in an &lt;code&gt;Error&lt;/code&gt; state, you can click the options icon (the three vertical dots) next to the connector. Then edit the configuration and restart the connector.&lt;/p&gt; &lt;h2&gt;Capture data change events from MongoDB&lt;/h2&gt; &lt;p&gt;Once the Debezium MongoDB connector is ready, it connects to the MongoDB database, creates a snapshot of the collections it monitors, and creates data change events for every record present in the collection.&lt;/p&gt; &lt;p&gt;To verify, use the message viewer in the OpenShift Streams for Apache Kafka web console.&lt;/p&gt; &lt;p&gt;Head over to the &lt;strong&gt;Application and Data Services&lt;/strong&gt; page of the Red Hat console and select &lt;strong&gt;Streams for Apache Kafka→Kafka Instances&lt;/strong&gt;. Click the name of the Streams for the Apache Kafka instance that you created for connectors. Select the &lt;strong&gt;Topics&lt;/strong&gt; tab.&lt;/p&gt; &lt;p&gt;You should see four new topics. Debezium connectors run on top of Kafka Connect (in contrast to the other OpenShift Connectors instances, which are based on Camel-K). Kafka Connect creates three topics to maintain its internal state. These are the topics ending with &lt;code&gt;-config&lt;/code&gt;, &lt;code&gt;-offset&lt;/code&gt;, and &lt;code&gt;-status&lt;/code&gt; shown in Figure 3.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/connectors-dbz-topics.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/connectors-dbz-topics.png?itok=Fq3nwp4K" width="1440" height="534" alt="The Kafka Connect connector creates four topics." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The Kafka Connect connector creates four topics. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;The other topic, named &lt;code&gt;mongo-mflix.sample_mflix.movies&lt;/code&gt;, holds the data change events from the movies collection. Click the topic name and select the &lt;strong&gt;Messages&lt;/strong&gt; tab. You should see the most recent ten messages in the topic, as shown in Figure 4.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/data-change-event-messages.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/data-change-event-messages.png?itok=EXj1cQO8" width="1440" height="793" alt="A topic's Messages tab displays recent messages in the topic." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: A topic's Messages tab displays recent messages in the topic. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;The offset of the last message in Figure 4 is 23529, which indicates that there are 23530 events in the topic. This corresponds to the number of records in the &lt;code&gt;movies&lt;/code&gt; collection.&lt;/p&gt; &lt;p&gt;Each data change message has a JSON payload with the following structure:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;after&lt;/strong&gt;: Contains the latest state of the document.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;source&lt;/strong&gt;: Contains metadata about the connector and the MongoDB instance.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;op&lt;/strong&gt;: Specifies the operation that created this change. In this case, the operation is &lt;code&gt;r&lt;/code&gt;, which stands for &lt;code&gt;read&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Please refer to the &lt;a href="https://debezium.io/documentation/reference/1.9/"&gt;Debezium documentation&lt;/a&gt; for more information on Debezium and the structure of the data change events it produces.&lt;/p&gt; &lt;p&gt;At this point, you can add new records to the MongoDB collection or modify existing records. The easiest way to do so is through the MongoDB Atlas web console:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;On the &lt;strong&gt;Database&lt;/strong&gt; page, select the &lt;strong&gt;Collections&lt;/strong&gt; tab&lt;/li&gt; &lt;li&gt;Then select the &lt;code&gt;sample_mflix.movies&lt;/code&gt; collection.&lt;/li&gt; &lt;li&gt;From here you can add new records to the collection or modify existing ones. Every time you make a change, a data change event is produced with the latest state of the document and an operation equal to &lt;code&gt;c&lt;/code&gt; for creates and &lt;code&gt;u&lt;/code&gt; for updates.&lt;/li&gt; &lt;li&gt;You can verify that change events are generated by checking the message viewer of the data change event topic in the Red Hat console.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;An end-to-end data pipeline example&lt;/h2&gt; &lt;p&gt;Capturing data change events from a database with an OpenShift Connector instance is just the first step in using the data. Typically, the data change events are consumed by other services or applications to, for instance, replicate the data or build a local view of the data.&lt;/p&gt; &lt;p&gt;The following video contains a demo of what an end-to-end data pipeline could look like. The demo uses OpenShift Connectors to stream the data change events to &lt;a href="https://aws.amazon.com/kinesis/"&gt;AWS Kinesis&lt;/a&gt;. The events trigger an AWS Lambda function that extracts the state of the document from the event and updates an AWS OpenSearch index. Figure 5 shows the pipeline.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/connectors-data-pipeline_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/connectors-data-pipeline_0.png?itok=CD0w0bc5" width="958" height="544" alt="A flow chart illustrating OpenShift Connectors feeds change events." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Red Hat OpenShift Connectors feeds change events from the database to consumers. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;h3&gt;Watch this quick CDC pipeline demo:&lt;/h3&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;OpenShift Connectors speed up data collection applications&lt;/h2&gt; &lt;p&gt;We hope you found this demonstration informative and easy to follow. Try &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/connectors"&gt;Red Hat OpenShift Connectors&lt;/a&gt; for yourself and see how they speed up data collection applications. Feel free to reach out to us. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/09/07/configuring-change-data-capture" title="Red Hat OpenShift Connectors: Configuring change data capture"&gt;Red Hat OpenShift Connectors: Configuring change data capture&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bernard Tison</dc:creator><dc:date>2022-09-07T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.12.1.Final released - Fixes a performance regression</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-12-1-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-12-1-final-released/</id><updated>2022-09-07T00:00:00Z</updated><content type="html">2.12.1.Final is the first maintenance release of the 2.12 release train. If you have already upgraded to 2.12, we highly recommend this upgrade as it fixes, amongst other things, a performance regression introduced in Quarkus 2.12.0.Final. It is a safe upgrade for anyone using 2.12. Migration Guide If you are...</content><dc:creator>Guillaume Smet</dc:creator></entry></feed>
